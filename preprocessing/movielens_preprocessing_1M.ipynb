{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zf15/rc7ne/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension: (1000209, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1     1193       5  978300760\n",
       "1        1      661       3  978302109\n",
       "2        1      914       3  978301968\n",
       "3        1     3408       4  978300275\n",
       "4        1     2355       5  978824291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"./data/ml-1m\"\n",
    "file_path = os.path.join(data_dir, 'ratings.dat')\n",
    "\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df_raw = pd.read_csv(file_path, sep = '::', names = names)\n",
    "\n",
    "value_col = \"rating\"\n",
    "user_col = \"user_id\"\n",
    "item_col = \"item_id\"\n",
    "print(\"dimension:\", df_raw.shape)\n",
    "df_raw.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_col = \"title\"\n",
    "# genre_col = \"genres\"\n",
    "\n",
    "# item_info_path = os.path.join(data_dir, \"movies.csv\")\n",
    "# df_item = pd.read_csv(item_info_path)\n",
    "# df_item = df_item[df_item[genre_col]!=\"(no genres listed)\"]\n",
    "# print(\"dimension: \", df_item.shape)\n",
    "# df_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = df_raw[df_raw[value_col] >= 4.0].copy()\n",
    "# df_rating = df_rating.merge(df_item, on=item_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove unpopular items and unpopular users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_user_item(df, uid_min, iid_min):\n",
    "    n_users = df[user_col].unique().shape[0]\n",
    "    n_items = df[item_col].unique().shape[0]\n",
    "    sparsity = float(df.shape[0])/float(n_users*n_items)*100\n",
    "    print(\"info\")\n",
    "    print(\"number of users: {}\".format(n_users))\n",
    "    print(\"number of items: {}\".format(n_items))\n",
    "    print(\"sparsity:{:4.4f}%\".format(sparsity))\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        starting_shape = df.shape[0]\n",
    "        item_counts = df.groupby(user_col)[item_col].count()\n",
    "        df = df[~df[user_col].isin(item_counts[item_counts < iid_min].index.tolist())]\n",
    "        user_counts = df.groupby(item_col)[user_col].count()\n",
    "        df = df[~df[item_col].isin(user_counts[user_counts < uid_min].index.tolist())]\n",
    "        ending_shape = df.shape[0]\n",
    "        if starting_shape == ending_shape:\n",
    "            done = True\n",
    "            \n",
    "    n_users = df[user_col].unique().shape[0]\n",
    "    n_items = df[item_col].unique().shape[0]\n",
    "    sparsity = float(df.shape[0])/float(n_users*n_items)*100\n",
    "    print(\"number of users: {}\".format(n_users))\n",
    "    print(\"number of items: {}\".format(n_items))\n",
    "    print(\"sparsity:{:4.4f}%\".format(sparsity))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "number of users: 6038\n",
      "number of items: 3533\n",
      "sparsity:2.6968%\n",
      "number of users: 5949\n",
      "number of items: 2810\n",
      "sparsity:3.4189%\n"
     ]
    }
   ],
   "source": [
    "user_min_num = 10\n",
    "item_min_num = 10\n",
    "new_df_rating = threshold_user_item(df_rating, user_min_num, item_min_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieId_to_iid = {}\n",
    "movieId_to_iid[\"<pad>\"] = 0\n",
    "iid_to_movieId = {}\n",
    "iid_to_movieId[0] = \"<pad>\"\n",
    "\n",
    "for (idx, movieId) in enumerate(new_df_rating[item_col].unique().tolist()):\n",
    "    movieId_to_iid[movieId] = idx+1\n",
    "    iid_to_movieId[idx+1] = movieId\n",
    "    \n",
    "userId_to_uid = {}\n",
    "userId_to_uid[\"<pad>\"] = 0\n",
    "uid_to_userId = {}\n",
    "uid_to_userId[0] = \"<pad>\"\n",
    "\n",
    "for (idx, userId) in enumerate(new_df_rating[user_col].unique().tolist()):\n",
    "    userId_to_uid[userId] = idx+1\n",
    "    uid_to_userId[idx+1] = userId "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_num: 5950\n",
      "item_num: 2811\n"
     ]
    }
   ],
   "source": [
    "user_num = len(uid_to_userId)\n",
    "item_num = len(iid_to_movieId)\n",
    "print(\"user_num:\", user_num)\n",
    "print(\"item_num:\", item_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_rating[\"user_id\"] = new_df_rating[user_col].apply(lambda x: userId_to_uid[x])\n",
    "new_df_rating[\"item_id\"] = new_df_rating[item_col].apply(lambda x: movieId_to_iid[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_itemlist_dict = new_df_rating.groupby([user_col]).item_id.apply(list)\n",
    "user_itemlist_dict = dict(user_itemlist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_itemlist = list(new_df_rating[item_col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(user_data):\n",
    "    neg_sample = 500\n",
    "    train = []\n",
    "    valid = []\n",
    "    test = []\n",
    "    \n",
    "    train_ratio = 0.8\n",
    "    valid_ratio = 0.9\n",
    "#     test_ratio = 0.1\n",
    "    \n",
    "    userlist = list(user_data.keys())\n",
    "    usernum = len(userlist)\n",
    "        \n",
    "    for i in range(usernum):\n",
    "        user_i = userlist[i]\n",
    "        \n",
    "        itemlist_i = user_data[user_i]\n",
    "        random.shuffle(itemlist_i)\n",
    "        itemnum_i = len(itemlist_i)\n",
    "        \n",
    "        valid_threshold = int(itemnum_i*train_ratio)\n",
    "        test_threshold = int(itemnum_i*valid_ratio)\n",
    "        \n",
    "        train_itemlist_i = itemlist_i[:valid_threshold]\n",
    "        valid_itemlist_i = itemlist_i[valid_threshold:test_threshold]\n",
    "        test_itemlist_i = itemlist_i[test_threshold:]\n",
    "        \n",
    "        train_negitemlist_i = set(train_itemlist_i)^set(train_itemlist)\n",
    "        train_negitemlist_i = list(train_negitemlist_i)\n",
    "        \n",
    "        for item_j in train_itemlist_i:\n",
    "            sampled_negitemlist_i = random.sample(train_negitemlist_i, k=neg_sample)\n",
    "            train.append([user_i, item_j, sampled_negitemlist_i])\n",
    "        \n",
    "        for item_j in valid_itemlist_i:\n",
    "            valid.append([user_i, item_j])\n",
    "            \n",
    "        for item_j in test_itemlist_i:\n",
    "            test.append([user_i, item_j])\n",
    "            \n",
    "    print(\"train_num\", len(train))\n",
    "    print(\"valid num\", len(valid))\n",
    "    print(\"test num\", len(test))\n",
    "    \n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num 454860\n",
      "valid num 56864\n",
      "test num 59807\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = split_train_test(user_itemlist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train num 454860\n",
      "valid num 56864\n",
      "test num 59807\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.columns=[\"userid\", \"pos_itemid\", \"neg_itemid\"]\n",
    "valid_df = pd.DataFrame(valid_data)\n",
    "valid_df.columns=[\"userid\", \"itemid\"]\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df.columns=[\"userid\", \"itemid\"]\n",
    "print(\"train num\", len(train_df))\n",
    "print(\"valid num\", len(valid_df))\n",
    "print(\"test num\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>pos_itemid</th>\n",
       "      <th>neg_itemid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[2467, 915, 1043, 621, 2731, 707, 2691, 800, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>[570, 1342, 2311, 1442, 276, 1398, 210, 1308, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>[1633, 188, 336, 1707, 2589, 2671, 948, 223, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>[2244, 997, 606, 1258, 1509, 2362, 82, 184, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[989, 815, 483, 1351, 1781, 2378, 1164, 1246, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  pos_itemid                                         neg_itemid\n",
       "0       1          38  [2467, 915, 1043, 621, 2731, 707, 2691, 800, 1...\n",
       "1       1          19  [570, 1342, 2311, 1442, 276, 1398, 210, 1308, ...\n",
       "2       1          16  [1633, 188, 336, 1707, 2589, 2671, 948, 223, 2...\n",
       "3       1          36  [2244, 997, 606, 1258, 1509, 2362, 82, 184, 27...\n",
       "4       1          17  [989, 815, 483, 1351, 1781, 2378, 1164, 1246, ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.pickle\"\n",
    "train_data_abs_file = os.path.join(data_dir, train_data_file)\n",
    "train_df.to_pickle(train_data_abs_file)\n",
    "\n",
    "valid_data_file = \"valid_data.pickle\"\n",
    "valid_data_abs_file = os.path.join(data_dir, valid_data_file)\n",
    "valid_df.to_pickle(valid_data_abs_file)\n",
    "\n",
    "test_data_file = \"test_data.pickle\"\n",
    "test_data_abs_file = os.path.join(data_dir, test_data_file)\n",
    "test_df.to_pickle(test_data_abs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId_to_uid = {str(k):str(userId_to_uid[k]) for k in userId_to_uid}\n",
    "movieId_to_iid = {str(k):str(movieId_to_iid[k]) for k in movieId_to_iid}\n",
    "\n",
    "uid_to_userId = {str(k):str(uid_to_userId[k]) for k in uid_to_userId}\n",
    "iid_to_movieId = {str(k):str(iid_to_movieId[k]) for k in iid_to_movieId}\n",
    "\n",
    "vocab = {\"userindex2uid\": userId_to_uid, \"uid2userindex\":uid_to_userId, \"itemindex2iid\": movieId_to_iid, \"iid2itemindex\":iid_to_movieId}\n",
    "vocab_file = \"vocab.json\"\n",
    "\n",
    "with open(os.path.join(data_dir, vocab_file), \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/ml-1m'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822 1\n"
     ]
    }
   ],
   "source": [
    "# train_df.userid.unique()\n",
    "print(max(train_df.pos_itemid.unique()), min(train_df.pos_itemid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2862, -1.0019,  0.0103,  0.0317],\n",
       "        [ 0.7306,  0.9805,  1.1846, -1.0710],\n",
       "        [-1.0851, -0.9494,  0.0846, -1.1893]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -inf,    -inf,  0.0103,  0.0317],\n",
       "        [ 0.7306,    -inf,    -inf,    -inf],\n",
       "        [-1.0851,    -inf,    -inf,    -inf]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[1, 0, 0], [2, 1, 3], [1, 2, 3]])\n",
    "a.scatter_(1, b, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -inf,    -inf,  0.0103,  0.0317],\n",
       "        [ 0.7306,    -inf,    -inf,    -inf],\n",
       "        [-1.0851,    -inf,    -inf,    -inf]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 0.0317],\n",
       "        [ 0.7306],\n",
       "        [-1.0851]]),\n",
       "indices=tensor([[3],\n",
       "        [0],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(a, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, 0] = float(\"-inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -inf,   -inf, 0.0103, 0.0317],\n",
       "        [  -inf,   -inf,   -inf,   -inf],\n",
       "        [  -inf,   -inf,   -inf,   -inf]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a[0].numpy() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
